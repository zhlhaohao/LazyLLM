|  | 

````class  Parallel(LazyLLMFlowsBase):
 """用于管理LazyLLMFlows中的并行流的类。   这个类继承自LazyLLMFlowsBase，提供了一个并行或顺序运行操作的接口。它支持使用线程进行并发执行，并允许以字典形式返回结果。     可以这样可视化 ``Parallel`` 类：   ```text #       /> module11 -> ... -> module1N -> out1 \\ # input -> module21 -> ... -> module2N -> out2 -> (out1, out2, out3) #       \> module31 -> ... -> module3N -> out3 / ```   可以这样可视化 ``Parallel.sequential`` 方法：   ```text # input -> module21 -> ... -> module2N -> out2 -> ```   Args:
 _scatter (bool, optional): 如果为 ``True``，输入将在项目之间分割。如果为 ``False``，相同的输入将传递给所有项目。默认为 ``False``。 _concurrent (bool, optional): 如果为 ``True``，操作将使用线程并发执行。如果为 ``False``，操作将顺序执行。默认为 ``True``。 args: 基类的可变长度参数列表。 kwargs: 基类的任意关键字参数。   <span style="font-size: 20px;">&ensp;**`asdict property`**</span>   标记Parellel，使得Parallel每次调用时的返回值由package变为dict。当使用 ``asdict`` 时，请务必保证parallel的元素被取了名字，例如:  ``parallel(name=value)`` 。   <span style="font-size: 20px;">&ensp;**`tuple property`**</span>   标记Parellel，使得Parallel每次调用时的返回值由package变为tuple。   <span style="font-size: 20px;">&ensp;**`list property`**</span>   标记Parellel，使得Parallel每次调用时的返回值由package变为list。   <span style="font-size: 20px;">&ensp;**`sum property`**</span>   标记Parellel，使得Parallel每次调用时的返回值做一次累加。   <span style="font-size: 20px;">&ensp;**`join(self, string)`**</span>   标记Parellel，使得Parallel每次调用时的返回值通过 ``string`` 做一次join。     Examples:
 >>> import lazyllm >>> test1 = lambda a: a + 1 >>> test2 = lambda a: a * 4 >>> test3 = lambda a: a / 2 >>> ppl = lazyllm.parallel(test1, test2, test3) >>> ppl(1) (2, 4, 0.5) >>> ppl = lazyllm.parallel(a=test1, b=test2, c=test3) >>> ppl(1) {2, 4, 0.5} >>> ppl = lazyllm.parallel(a=test1, b=test2, c=test3).asdict >>> ppl(2) {'a': 3, 'b': 8, 'c': 1.0} >>> ppl = lazyllm.parallel(a=test1, b=test2, c=test3).astuple >>> ppl(-1) (0, -4, -0.5) >>> ppl = lazyllm.parallel(a=test1, b=test2, c=test3).aslist >>> ppl(0) [1, 0, 0.0] >>> ppl = lazyllm.parallel(a=test1, b=test2, c=test3).join('\\n') >>> ppl(1) '2\\n4\\n0.5' """   @staticmethod def  _worker(func, barrier, global_data, *args, **kw): # When multiple threads or processes use the same pipeline, all threads share the same pipeline ID, # making it impossible to distinguish between them based on the pipeline ID when saving intermediate # results. To address this, we assign a new session ID to each thread to store the intermediate # results of each pipeline. Note that when running in parallel, the execution order of modules is not # guaranteed, so TODO(wangzhihong) streaming output via FileSystemQueue is not possible. lazyllm.globals._init_sid() lazyllm.globals._update(global_data) lazyllm.globals['bind_args'] = lazyllm.globals['bind_args'].copy() _barr.impl = barrier r = func(*args, **kw) lazyllm.globals.clear() return r   class  PostProcessType(Enum): NONE = 0 DICT = 1 TUPLE = 2 LIST = 3 SUM = 4 JOIN = 5   def  __init__(self, *args, _scatter: bool = False, _concurrent: Union[bool, int] = True, multiprocessing: bool = False, auto_capture: bool = False, **kw): super().__init__(*args, **kw, auto_capture=auto_capture) self._post_process_type = Parallel.PostProcessType.NONE self._post_process_args = None self._multiprocessing = multiprocessing or config['parallel_multiprocessing'] self._concurrent = 0 if not _concurrent else 5 if isinstance(_concurrent, bool) else _concurrent self._scatter = _scatter   @staticmethod def  _set_status(self, type, args=None): assert self._post_process_type is Parallel.PostProcessType.NONE, 'Cannor set post process twice' self._post_process_type = type self._post_process_args = args return self   asdict = property(partial(_set_status, type=PostProcessType.DICT)) astuple = property(partial(_set_status, type=PostProcessType.TUPLE)) aslist = property(partial(_set_status, type=PostProcessType.LIST)) sum = property(partial(_set_status, type=PostProcessType.SUM))   def  join(self, string=''): assert isinstance(string, str), 'argument of join shoule be str' return Parallel._set_status(self, type=Parallel.PostProcessType.JOIN, args=string)   @classmethod def  sequential(cls, *args, **kw): return cls(*args, _concurrent=False, **kw)   def  _run(self, __input, items=None, **kw): if items is None: items = self._items size = len(items) if self._scatter: inputs = _split_input(__input, self._item_names if self._item_names else size) else: inputs = [__input] * size else: inputs = __input   if self._concurrent: if self._multiprocessing: barrier, executor = None, lazyllm.ProcessPoolExecutor else: barrier, executor = threading.Barrier(len(items)), concurrent.futures.ThreadPoolExecutor   with executor(max_workers=self._concurrent) as e: futures = [e.submit(partial(self._worker, self.invoke, barrier, lazyllm.globals._data, it, inp, **kw)) for it, inp in zip(items, inputs)] if (not_done := concurrent.futures.wait(futures).not_done): error_msgs = [] for future in not_done: if (exc := future.exception()) is not None: if (tb := getattr(future, "_traceback", None)): tb_str = ''.join(traceback.format_exception(type(exc), exc, tb)) else: tb_str = ''.join(traceback.format_exception(type(exc), exc, exc.__traceback__)) error_msgs.append(f"Future: {future}\n{tb_str}") else: error_msgs.append(f"Future: {future} not complete without exception。") raise RuntimeError('Parallel execute failed!\n' + '\n'.join(error_msgs)) return package([future.result() for future in futures]) else: return package(self.invoke(it, inp, **kw) for it, inp in zip(items, inputs))   def  _post_process(self, output): if self._post_process_type == Parallel.PostProcessType.DICT: assert self._item_names, 'Item name should be set when you want to return dict.' output = {k: v for k, v in zip(self._item_names, output)} elif self._post_process_type == Parallel.PostProcessType.TUPLE: output = tuple(output) elif self._post_process_type == Parallel.PostProcessType.LIST: output = list(output) elif self._post_process_type == Parallel.PostProcessType.SUM: output = ''.join([str(i) for i in output]) if isinstance(output[0], str) else sum(output, type(output[0])()) elif self._post_process_type == Parallel.PostProcessType.JOIN: output = self._post_process_args.join([str(i) for i in output]) return output```` 



 |