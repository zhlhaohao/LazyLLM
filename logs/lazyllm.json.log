{"text": "message: {'choices': [{'message': {'content': \"Plan: Identify the main ingredient in The Hennchata and find out which cognac house produces it. Since The Hennchata is a specific drink, we need to gather information about its ingredients and the brand associated with it.\\n#E1 = WikipediaWorker[The Hennchata]\\nPlan: From the retrieved information, determine the cognac house that makes the main ingredient. If the Wikipedia article doesn't directly mention this, use general knowledge and inference to identify the cognac house.\\n#E2 = LLMWorker[What is the name of the cognac house that makes the main ingredient in The Hennchata, given #E1?]\", 'role': 'assistant'}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None}], 'object': 'chat.completion', 'usage': {'prompt_tokens': 464, 'completion_tokens': 135, 'total_tokens': 599}, 'created': 1753779624, 'system_fingerprint': None, 'model': 'qwen-max-latest', 'id': 'chatcmpl-d1d7fb92-5c60-9cc5-8bdc-436dd27ed021'}\n", "record": {"elapsed": {"repr": "0:00:23.073281", "seconds": 23.073281}, "exception": null, "extra": {"name": "lazyllm", "process": 159449}, "file": {"name": "onlineChatModuleBase.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/module/llms/onlineChatModule/onlineChatModuleBase.py"}, "function": "_str_to_json", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 204, "message": "message: {'choices': [{'message': {'content': \"Plan: Identify the main ingredient in The Hennchata and find out which cognac house produces it. Since The Hennchata is a specific drink, we need to gather information about its ingredients and the brand associated with it.\\n#E1 = WikipediaWorker[The Hennchata]\\nPlan: From the retrieved information, determine the cognac house that makes the main ingredient. If the Wikipedia article doesn't directly mention this, use general knowledge and inference to identify the cognac house.\\n#E2 = LLMWorker[What is the name of the cognac house that makes the main ingredient in The Hennchata, given #E1?]\", 'role': 'assistant'}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None}], 'object': 'chat.completion', 'usage': {'prompt_tokens': 464, 'completion_tokens': 135, 'total_tokens': 599}, 'created': 1753779624, 'system_fingerprint': None, 'model': 'qwen-max-latest', 'id': 'chatcmpl-d1d7fb92-5c60-9cc5-8bdc-436dd27ed021'}", "module": "onlineChatModuleBase", "name": "lazyllm.module.llms.onlineChatModule.onlineChatModuleBase", "process": {"id": 159449, "name": "MainProcess"}, "thread": {"id": 140273490595840, "name": "MainThread"}, "time": {"repr": "2025-07-29 17:00:23.188707+08:00", "timestamp": 1753779623.188707}}}
{"text": "result: Plan: Identify the main ingredient in The Hennchata and find out which cognac house produces it. Since The Hennchata is a specific drink, we need to gather information about its ingredients and the brand associated with it.\n#E1 = WikipediaWorker[The Hennchata]\nPlan: From the retrieved information, determine the cognac house that makes the main ingredient. If the Wikipedia article doesn't directly mention this, use general knowledge and inference to identify the cognac house.\n#E2 = LLMWorker[What is the name of the cognac house that makes the main ingredient in The Hennchata, given #E1?]\n", "record": {"elapsed": {"repr": "0:00:23.075220", "seconds": 23.07522}, "exception": null, "extra": {"name": "lazyllm", "process": 159449}, "file": {"name": "onlineChatModuleBase.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/module/llms/onlineChatModule/onlineChatModuleBase.py"}, "function": "_extract_and_format", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 267, "message": "result: Plan: Identify the main ingredient in The Hennchata and find out which cognac house produces it. Since The Hennchata is a specific drink, we need to gather information about its ingredients and the brand associated with it.\n#E1 = WikipediaWorker[The Hennchata]\nPlan: From the retrieved information, determine the cognac house that makes the main ingredient. If the Wikipedia article doesn't directly mention this, use general knowledge and inference to identify the cognac house.\n#E2 = LLMWorker[What is the name of the cognac house that makes the main ingredient in The Hennchata, given #E1?]", "module": "onlineChatModuleBase", "name": "lazyllm.module.llms.onlineChatModule.onlineChatModuleBase", "process": {"id": 159449, "name": "MainProcess"}, "thread": {"id": 140273490595840, "name": "MainThread"}, "time": {"repr": "2025-07-29 17:00:23.190646+08:00", "timestamp": 1753779623.190646}}}
{"text": "planner plans: Plan: Identify the main ingredient in The Hennchata and find out which cognac house produces it. Since The Hennchata is a specific drink, we need to gather information about its ingredients and the brand associated with it.\n#E1 = WikipediaWorker[The Hennchata]\nPlan: From the retrieved information, determine the cognac house that makes the main ingredient. If the Wikipedia article doesn't directly mention this, use general knowledge and inference to identify the cognac house.\n#E2 = LLMWorker[What is the name of the cognac house that makes the main ingredient in The Hennchata, given #E1?]\n", "record": {"elapsed": {"repr": "0:00:23.077081", "seconds": 23.077081}, "exception": null, "extra": {"name": "lazyllm", "process": 159449}, "file": {"name": "rewooAgent.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/tools/agent/rewooAgent.py"}, "function": "_parse_plan", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 64, "message": "planner plans: Plan: Identify the main ingredient in The Hennchata and find out which cognac house produces it. Since The Hennchata is a specific drink, we need to gather information about its ingredients and the brand associated with it.\n#E1 = WikipediaWorker[The Hennchata]\nPlan: From the retrieved information, determine the cognac house that makes the main ingredient. If the Wikipedia article doesn't directly mention this, use general knowledge and inference to identify the cognac house.\n#E2 = LLMWorker[What is the name of the cognac house that makes the main ingredient in The Hennchata, given #E1?]", "module": "rewooAgent", "name": "lazyllm.tools.agent.rewooAgent", "process": {"id": 159449, "name": "MainProcess"}, "thread": {"id": 140273490595840, "name": "MainThread"}, "time": {"repr": "2025-07-29 17:00:23.192507+08:00", "timestamp": 1753779623.192507}}}
{"text": "An error occored when invoking `<class 'lazyllm.flow.flow._FuncWrap'>(<Function type=_get_worker_evidences>)` with input <class 'lazyllm.common.common.package'>`(['Plan: Identify the main ingredient in The Hennchata and find out which cognac house produces it. Since The Hennchata is a specific drink, we need to gather information about its ingredients and the brand associated with it.', \"Plan: From the retrieved information, determine the cognac house that makes the main ingredient. If the Wikipedia article doesn't directly mention this, use general knowledge and inference to identify the cognac house.\"], {'#E1': 'WikipediaWorker[The Hennchata]', '#E2': 'LLMWorker[What is the name of the cognac house that makes the main ingredient in The Hennchata, given #E1?]'})` and kw `{}`\n", "record": {"elapsed": {"repr": "0:02:42.444354", "seconds": 162.444354}, "exception": null, "extra": {"name": "lazyllm", "process": 159449}, "file": {"name": "flow.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/flow/flow.py"}, "function": "invoke", "level": {"icon": "‚ùå", "name": "ERROR", "no": 40}, "line": 252, "message": "An error occored when invoking `<class 'lazyllm.flow.flow._FuncWrap'>(<Function type=_get_worker_evidences>)` with input <class 'lazyllm.common.common.package'>`(['Plan: Identify the main ingredient in The Hennchata and find out which cognac house produces it. Since The Hennchata is a specific drink, we need to gather information about its ingredients and the brand associated with it.', \"Plan: From the retrieved information, determine the cognac house that makes the main ingredient. If the Wikipedia article doesn't directly mention this, use general knowledge and inference to identify the cognac house.\"], {'#E1': 'WikipediaWorker[The Hennchata]', '#E2': 'LLMWorker[What is the name of the cognac house that makes the main ingredient in The Hennchata, given #E1?]'})` and kw `{}`", "module": "flow", "name": "lazyllm.flow.flow", "process": {"id": 159449, "name": "MainProcess"}, "thread": {"id": 140273490595840, "name": "MainThread"}, "time": {"repr": "2025-07-29 17:02:42.559780+08:00", "timestamp": 1753779762.55978}}}
{"text": "Error type: RuntimeError, Error message: \nAn error occured in <class 'lazyllm.common.registry.WikipediaWorkerTool'> with name WikipediaWorker.\nArgs:\n('The Hennchata',)\nKwargs\n{}\nError messages:\nHTTPConnectionPool(host='en.wikipedia.org', port=80): Max retries exceeded with url: /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=The+Hennchata&srinfo=suggestion&format=json&action=query (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f93bdd1eda0>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)'))\nOriginal traceback:\n  File \"/home/lianghao/github/LazyLLM/lazyllm/module/module.py\", line 129, in __call__\n    else self.forward(*args, **kw)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/tools/agent/toolsManager.py\", line 167, in forward\n    ret = self.apply(**val_input)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/common/registry.py\", line 126, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/examples/chapter18/ReWOOAgent.py\", line 15, in WikipediaWorker\n    evidence = wikipedia.page(input).content\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 270, in page\n    results, suggestion = search(title, results=1, suggestion=True)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/util.py\", line 28, in __call__\n    ret = self._cache[key] = self.fn(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 103, in search\n    raw_results = _wiki_request(search_params)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 737, in _wiki_request\n    r = requests.get(API_URL, params=params, headers=headers)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 33, in _get\n    def _get(url, params=None, **kwargs): return request(\"get\", url, params=params, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 30, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\n\nTraceback: Traceback (most recent call last):\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n    raise err\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n    sock.connect(sa)\nTimeoutError: [Errno 110] Connection timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n    conn.request(\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connection.py\", line 494, in request\n    self.endheaders()\n  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n    self.send(msg)\n  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n    self.connect()\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connection.py\", line 325, in connect\n    self.sock = self._new_conn()\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connection.py\", line 207, in _new_conn\n    raise ConnectTimeoutError(\nurllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f93bdd1eda0>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/util/retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='en.wikipedia.org', port=80): Max retries exceeded with url: /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=The+Hennchata&srinfo=suggestion&format=json&action=query (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f93bdd1eda0>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/lianghao/github/LazyLLM/lazyllm/module/module.py\", line 129, in __call__\n    else self.forward(*args, **kw)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/tools/agent/toolsManager.py\", line 167, in forward\n    ret = self.apply(**val_input)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/common/registry.py\", line 126, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/examples/chapter18/ReWOOAgent.py\", line 15, in WikipediaWorker\n    evidence = wikipedia.page(input).content\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 270, in page\n    results, suggestion = search(title, results=1, suggestion=True)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/util.py\", line 28, in __call__\n    ret = self._cache[key] = self.fn(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 103, in search\n    raw_results = _wiki_request(search_params)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 737, in _wiki_request\n    r = requests.get(API_URL, params=params, headers=headers)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 33, in _get\n    def _get(url, params=None, **kwargs): return request(\"get\", url, params=params, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 30, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\nrequests.exceptions.ConnectTimeout: HTTPConnectionPool(host='en.wikipedia.org', port=80): Max retries exceeded with url: /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=The+Hennchata&srinfo=suggestion&format=json&action=query (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f93bdd1eda0>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/lianghao/github/LazyLLM/lazyllm/flow/flow.py\", line 248, in invoke\n    return it(*__input, **kw) if isinstance(__input, package) else it(**__input, **kw)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/flow/flow.py\", line 26, in __call__\n    def __call__(self, *args, **kw): return self._f(*args, **kw)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/tools/agent/rewooAgent.py\", line 93, in _get_worker_evidences\n    worker_evidences[e] = tool_instance(tool_input)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/module/module.py\", line 134, in __call__\n    raise RuntimeError(\nRuntimeError: \nAn error occured in <class 'lazyllm.common.registry.WikipediaWorkerTool'> with name WikipediaWorker.\nArgs:\n('The Hennchata',)\nKwargs\n{}\nError messages:\nHTTPConnectionPool(host='en.wikipedia.org', port=80): Max retries exceeded with url: /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=The+Hennchata&srinfo=suggestion&format=json&action=query (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f93bdd1eda0>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)'))\nOriginal traceback:\n  File \"/home/lianghao/github/LazyLLM/lazyllm/module/module.py\", line 129, in __call__\n    else self.forward(*args, **kw)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/tools/agent/toolsManager.py\", line 167, in forward\n    ret = self.apply(**val_input)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/common/registry.py\", line 126, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/examples/chapter18/ReWOOAgent.py\", line 15, in WikipediaWorker\n    evidence = wikipedia.page(input).content\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 270, in page\n    results, suggestion = search(title, results=1, suggestion=True)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/util.py\", line 28, in __call__\n    ret = self._cache[key] = self.fn(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 103, in search\n    raw_results = _wiki_request(search_params)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 737, in _wiki_request\n    r = requests.get(API_URL, params=params, headers=headers)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 33, in _get\n    def _get(url, params=None, **kwargs): return request(\"get\", url, params=params, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 30, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\n\n\n", "record": {"elapsed": {"repr": "0:02:42.449883", "seconds": 162.449883}, "exception": null, "extra": {"name": "lazyllm", "process": 159449}, "file": {"name": "flow.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/flow/flow.py"}, "function": "invoke", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 256, "message": "Error type: RuntimeError, Error message: \nAn error occured in <class 'lazyllm.common.registry.WikipediaWorkerTool'> with name WikipediaWorker.\nArgs:\n('The Hennchata',)\nKwargs\n{}\nError messages:\nHTTPConnectionPool(host='en.wikipedia.org', port=80): Max retries exceeded with url: /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=The+Hennchata&srinfo=suggestion&format=json&action=query (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f93bdd1eda0>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)'))\nOriginal traceback:\n  File \"/home/lianghao/github/LazyLLM/lazyllm/module/module.py\", line 129, in __call__\n    else self.forward(*args, **kw)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/tools/agent/toolsManager.py\", line 167, in forward\n    ret = self.apply(**val_input)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/common/registry.py\", line 126, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/examples/chapter18/ReWOOAgent.py\", line 15, in WikipediaWorker\n    evidence = wikipedia.page(input).content\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 270, in page\n    results, suggestion = search(title, results=1, suggestion=True)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/util.py\", line 28, in __call__\n    ret = self._cache[key] = self.fn(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 103, in search\n    raw_results = _wiki_request(search_params)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 737, in _wiki_request\n    r = requests.get(API_URL, params=params, headers=headers)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 33, in _get\n    def _get(url, params=None, **kwargs): return request(\"get\", url, params=params, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 30, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\n\nTraceback: Traceback (most recent call last):\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n    raise err\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n    sock.connect(sa)\nTimeoutError: [Errno 110] Connection timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n    conn.request(\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connection.py\", line 494, in request\n    self.endheaders()\n  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n    self.send(msg)\n  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n    self.connect()\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connection.py\", line 325, in connect\n    self.sock = self._new_conn()\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connection.py\", line 207, in _new_conn\n    raise ConnectTimeoutError(\nurllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f93bdd1eda0>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/urllib3/util/retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='en.wikipedia.org', port=80): Max retries exceeded with url: /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=The+Hennchata&srinfo=suggestion&format=json&action=query (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f93bdd1eda0>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/lianghao/github/LazyLLM/lazyllm/module/module.py\", line 129, in __call__\n    else self.forward(*args, **kw)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/tools/agent/toolsManager.py\", line 167, in forward\n    ret = self.apply(**val_input)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/common/registry.py\", line 126, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/examples/chapter18/ReWOOAgent.py\", line 15, in WikipediaWorker\n    evidence = wikipedia.page(input).content\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 270, in page\n    results, suggestion = search(title, results=1, suggestion=True)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/util.py\", line 28, in __call__\n    ret = self._cache[key] = self.fn(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 103, in search\n    raw_results = _wiki_request(search_params)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 737, in _wiki_request\n    r = requests.get(API_URL, params=params, headers=headers)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 33, in _get\n    def _get(url, params=None, **kwargs): return request(\"get\", url, params=params, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 30, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\nrequests.exceptions.ConnectTimeout: HTTPConnectionPool(host='en.wikipedia.org', port=80): Max retries exceeded with url: /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=The+Hennchata&srinfo=suggestion&format=json&action=query (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f93bdd1eda0>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/lianghao/github/LazyLLM/lazyllm/flow/flow.py\", line 248, in invoke\n    return it(*__input, **kw) if isinstance(__input, package) else it(**__input, **kw)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/flow/flow.py\", line 26, in __call__\n    def __call__(self, *args, **kw): return self._f(*args, **kw)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/tools/agent/rewooAgent.py\", line 93, in _get_worker_evidences\n    worker_evidences[e] = tool_instance(tool_input)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/module/module.py\", line 134, in __call__\n    raise RuntimeError(\nRuntimeError: \nAn error occured in <class 'lazyllm.common.registry.WikipediaWorkerTool'> with name WikipediaWorker.\nArgs:\n('The Hennchata',)\nKwargs\n{}\nError messages:\nHTTPConnectionPool(host='en.wikipedia.org', port=80): Max retries exceeded with url: /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=The+Hennchata&srinfo=suggestion&format=json&action=query (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f93bdd1eda0>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)'))\nOriginal traceback:\n  File \"/home/lianghao/github/LazyLLM/lazyllm/module/module.py\", line 129, in __call__\n    else self.forward(*args, **kw)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/tools/agent/toolsManager.py\", line 167, in forward\n    ret = self.apply(**val_input)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/common/registry.py\", line 126, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/examples/chapter18/ReWOOAgent.py\", line 15, in WikipediaWorker\n    evidence = wikipedia.page(input).content\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 270, in page\n    results, suggestion = search(title, results=1, suggestion=True)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/util.py\", line 28, in __call__\n    ret = self._cache[key] = self.fn(*args, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 103, in search\n    raw_results = _wiki_request(search_params)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/wikipedia/wikipedia.py\", line 737, in _wiki_request\n    r = requests.get(API_URL, params=params, headers=headers)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 33, in _get\n    def _get(url, params=None, **kwargs): return request(\"get\", url, params=params, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/lazyllm/patch.py\", line 30, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/home/lianghao/github/LazyLLM/.venv/lib/python3.10/site-packages/requests/adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\n\n", "module": "flow", "name": "lazyllm.flow.flow", "process": {"id": 159449, "name": "MainProcess"}, "thread": {"id": 140273490595840, "name": "MainThread"}, "time": {"repr": "2025-07-29 17:02:42.565309+08:00", "timestamp": 1753779762.565309}}}
{"text": "DocManager use file-system monitoring worker: True\n", "record": {"elapsed": {"repr": "0:00:02.372521", "seconds": 2.372521}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "utils.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/tools/rag/utils.py"}, "function": "__init__", "level": {"icon": "‚ÑπÔ∏è", "name": "INFO", "no": 20}, "line": 120, "message": "DocManager use file-system monitoring worker: True", "module": "utils", "name": "lazyllm.tools.rag.utils", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140542017499136, "name": "MainThread"}, "time": {"repr": "2025-07-29 17:08:30.363528+08:00", "timestamp": 1753780110.363528}}}
{"text": "the current pymilvus version is 2.4.15, use_iterator is True\n", "record": {"elapsed": {"repr": "0:00:07.354792", "seconds": 7.354792}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "milvus_store.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/tools/rag/store/milvus_store.py"}, "function": "_load_all_nodes_to", "level": {"icon": "‚ÑπÔ∏è", "name": "INFO", "no": 20}, "line": 334, "message": "the current pymilvus version is 2.4.15, use_iterator is True", "module": "milvus_store", "name": "lazyllm.tools.rag.store.milvus_store", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140542017499136, "name": "MainThread"}, "time": {"repr": "2025-07-29 17:08:35.345799+08:00", "timestamp": 1753780115.345799}}}
{"text": "LazyLLM webmodule launched successfully: Running on: http://0.0.0.0:23459, local URL: http://127.0.0.1:23459\n", "record": {"elapsed": {"repr": "0:00:08.123988", "seconds": 8.123988}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "webmodule.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/tools/webpages/webmodule.py"}, "function": "_work", "level": {"icon": "‚úÖ", "name": "SUCCESS", "no": 25}, "line": 412, "message": "LazyLLM webmodule launched successfully: Running on: http://0.0.0.0:23459, local URL: http://127.0.0.1:23459", "module": "webmodule", "name": "lazyllm.tools.webpages.webmodule", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140542017499136, "name": "MainThread"}, "time": {"repr": "2025-07-29 17:08:36.114995+08:00", "timestamp": 1753780116.114995}}}
{"text": "message: {'model': 'qwen3-32b', 'requestId': '1f58bd82-9fc1-40b7-854a-591d93fef64c', 'object': 'chat.completion.chunk', 'choices': [{'index': '0', 'message': {'role': 'assistant', 'content': ''}, 'finishReason': None}], 'created': '1753780160'}\n", "record": {"elapsed": {"repr": "0:00:50.585408", "seconds": 50.585408}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "onlineChatModuleBase.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/module/llms/onlineChatModule/onlineChatModuleBase.py"}, "function": "_str_to_json", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 204, "message": "message: {'model': 'qwen3-32b', 'requestId': '1f58bd82-9fc1-40b7-854a-591d93fef64c', 'object': 'chat.completion.chunk', 'choices': [{'index': '0', 'message': {'role': 'assistant', 'content': ''}, 'finishReason': None}], 'created': '1753780160'}", "module": "onlineChatModuleBase", "name": "lazyllm.module.llms.onlineChatModule.onlineChatModuleBase", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140539844355648, "name": "ThreadPoolExecutor-1_0"}, "time": {"repr": "2025-07-29 17:09:18.576415+08:00", "timestamp": 1753780158.576415}}}
{"text": "message: {'model': 'qwen3-32b', 'requestId': '1f58bd82-9fc1-40b7-854a-591d93fef64c', 'object': 'chat.completion.chunk', 'choices': [{'index': '0', 'message': {'content': 'ËÆ∫Êñá'}, 'finishReason': None}], 'created': '1753780160'}\n", "record": {"elapsed": {"repr": "0:00:50.649263", "seconds": 50.649263}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "onlineChatModuleBase.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/module/llms/onlineChatModule/onlineChatModuleBase.py"}, "function": "_str_to_json", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 204, "message": "message: {'model': 'qwen3-32b', 'requestId': '1f58bd82-9fc1-40b7-854a-591d93fef64c', 'object': 'chat.completion.chunk', 'choices': [{'index': '0', 'message': {'content': 'ËÆ∫Êñá'}, 'finishReason': None}], 'created': '1753780160'}", "module": "onlineChatModuleBase", "name": "lazyllm.module.llms.onlineChatModule.onlineChatModuleBase", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140539844355648, "name": "ThreadPoolExecutor-1_0"}, "time": {"repr": "2025-07-29 17:09:18.640270+08:00", "timestamp": 1753780158.64027}}}
{"text": "message: {'model': 'qwen3-32b', 'requestId': '1f58bd82-9fc1-40b7-854a-591d93fef64c', 'object': 'chat.completion.chunk', 'choices': [{'index': '0', 'message': {'content': 'ÈóÆÁ≠î'}, 'finishReason': None}], 'created': '1753780160'}\n", "record": {"elapsed": {"repr": "0:00:50.659497", "seconds": 50.659497}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "onlineChatModuleBase.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/module/llms/onlineChatModule/onlineChatModuleBase.py"}, "function": "_str_to_json", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 204, "message": "message: {'model': 'qwen3-32b', 'requestId': '1f58bd82-9fc1-40b7-854a-591d93fef64c', 'object': 'chat.completion.chunk', 'choices': [{'index': '0', 'message': {'content': 'ÈóÆÁ≠î'}, 'finishReason': None}], 'created': '1753780160'}", "module": "onlineChatModuleBase", "name": "lazyllm.module.llms.onlineChatModule.onlineChatModuleBase", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140539844355648, "name": "ThreadPoolExecutor-1_0"}, "time": {"repr": "2025-07-29 17:09:18.650504+08:00", "timestamp": 1753780158.650504}}}
{"text": "message: {'model': 'qwen3-32b', 'requestId': '1f58bd82-9fc1-40b7-854a-591d93fef64c', 'object': 'chat.completion.chunk', 'choices': [{'index': '0', 'message': {'content': ''}, 'finishReason': 'stop'}], 'created': '1753780160'}\n", "record": {"elapsed": {"repr": "0:00:50.666167", "seconds": 50.666167}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "onlineChatModuleBase.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/module/llms/onlineChatModule/onlineChatModuleBase.py"}, "function": "_str_to_json", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 204, "message": "message: {'model': 'qwen3-32b', 'requestId': '1f58bd82-9fc1-40b7-854a-591d93fef64c', 'object': 'chat.completion.chunk', 'choices': [{'index': '0', 'message': {'content': ''}, 'finishReason': 'stop'}], 'created': '1753780160'}", "module": "onlineChatModuleBase", "name": "lazyllm.module.llms.onlineChatModule.onlineChatModuleBase", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140539844355648, "name": "ThreadPoolExecutor-1_0"}, "time": {"repr": "2025-07-29 17:09:18.657174+08:00", "timestamp": 1753780158.657174}}}
{"text": "message: {'model': 'qwen3-32b', 'requestId': '1f58bd82-9fc1-40b7-854a-591d93fef64c', 'object': 'chat.completion.chunk', 'choices': [], 'created': '1753780160', 'usage': {'promptTokens': 310, 'completionTokens': 2, 'totalTokens': 312}}\n", "record": {"elapsed": {"repr": "0:00:50.669656", "seconds": 50.669656}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "onlineChatModuleBase.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/module/llms/onlineChatModule/onlineChatModuleBase.py"}, "function": "_str_to_json", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 204, "message": "message: {'model': 'qwen3-32b', 'requestId': '1f58bd82-9fc1-40b7-854a-591d93fef64c', 'object': 'chat.completion.chunk', 'choices': [], 'created': '1753780160', 'usage': {'promptTokens': 310, 'completionTokens': 2, 'totalTokens': 312}}", "module": "onlineChatModuleBase", "name": "lazyllm.module.llms.onlineChatModule.onlineChatModuleBase", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140539844355648, "name": "ThreadPoolExecutor-1_0"}, "time": {"repr": "2025-07-29 17:09:18.660663+08:00", "timestamp": 1753780158.660663}}}
{"text": "result: ËÆ∫ÊñáÈóÆÁ≠î\n", "record": {"elapsed": {"repr": "0:00:50.678556", "seconds": 50.678556}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "onlineChatModuleBase.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/module/llms/onlineChatModule/onlineChatModuleBase.py"}, "function": "_extract_and_format", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 267, "message": "result: ËÆ∫ÊñáÈóÆÁ≠î", "module": "onlineChatModuleBase", "name": "lazyllm.module.llms.onlineChatModule.onlineChatModuleBase", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140539844355648, "name": "ThreadPoolExecutor-1_0"}, "time": {"repr": "2025-07-29 17:09:18.669563+08:00", "timestamp": 1753780158.669563}}}
{"text": "Rerank use `ModuleReranker` and get nodes: [<Node id=fa991aeb-d691-4cc2-96b9-ae4e0101accc>, <Node id=717f1055-7b83-4fcb-8aba-7c37d48ca56a>, <Node id=f9763bf5-4b23-4035-976b-28676a3d0910>, <Node id=f3d018f3-48ac-4a56-897e-9fced0781094>, <Node id=5ab04080-bf98-4741-89d8-81266a949d8f>, <Node id=7a0d0e0d-6603-4592-8220-966492e1caa3>, <Node id=76282ea0-c8f9-4abd-a46e-95766dff2192>, <Node id=96e890d8-4d6d-4e9b-bb04-940dbfffbc92>, <Node id=ed780753-c937-4f88-bab7-649745eef6ac>, <Node id=740c2bd4-dfe4-4301-8460-9a1cb28eaae6>]\n", "record": {"elapsed": {"repr": "0:00:53.003868", "seconds": 53.003868}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "rerank.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/tools/rag/rerank.py"}, "function": "forward", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 121, "message": "Rerank use `ModuleReranker` and get nodes: [<Node id=fa991aeb-d691-4cc2-96b9-ae4e0101accc>, <Node id=717f1055-7b83-4fcb-8aba-7c37d48ca56a>, <Node id=f9763bf5-4b23-4035-976b-28676a3d0910>, <Node id=f3d018f3-48ac-4a56-897e-9fced0781094>, <Node id=5ab04080-bf98-4741-89d8-81266a949d8f>, <Node id=7a0d0e0d-6603-4592-8220-966492e1caa3>, <Node id=76282ea0-c8f9-4abd-a46e-95766dff2192>, <Node id=96e890d8-4d6d-4e9b-bb04-940dbfffbc92>, <Node id=ed780753-c937-4f88-bab7-649745eef6ac>, <Node id=740c2bd4-dfe4-4301-8460-9a1cb28eaae6>]", "module": "rerank", "name": "lazyllm.tools.rag.rerank", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140539844355648, "name": "ThreadPoolExecutor-1_0"}, "time": {"repr": "2025-07-29 17:09:20.994875+08:00", "timestamp": 1753780160.994875}}}
{"text": "message: {'choices': [{'message': {'content': 'ËøôÁØáËÆ∫Êñá„ÄäLearning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs„ÄãÁöÑ‰∏ªË¶Å‰∏ªÈ¢òËßÇÁÇπÂíåÂàõÊñ∞ÁÇπÂ¶Ç‰∏ãÔºö\\n\\n### ‰∏ªÈ¢òËßÇÁÇπ\\n1. **ÂÆâÂÖ®ÂØπÈΩêÁöÑÊåëÊàò**ÔºöÈöèÁùÄÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Ëá™‰∏ªÁ≥ªÁªü‰∏≠ÁöÑÂπøÊ≥õÂ∫îÁî®ÔºåÁ°Æ‰øùÂÖ∂ÂÆâÂÖ®ÊÄßÂèòÂæóÂ∞§‰∏∫ÈáçË¶Å„ÄÇÂ∞ΩÁÆ°Â∑≤ÊúâÂ§ßÈáèÁ†îÁ©∂Ëá¥Âäõ‰∫éÊèêÂçáLLMsÁöÑÂÆâÂÖ®ÊÄßÔºå‰ΩÜÊîªÂáªËÄÖ‰ªçËÉΩÈÄöËøá‚ÄúË∂äÁã±‚ÄùÊâãÊÆµÁªïËøáËøô‰∫õÂÆâÂÖ®Êé™ÊñΩ„ÄÇ\\n2. **ÂØπÊäóÂêéÁºÄÁöÑÁîüÊàê**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊñπÊ≥ïÔºåÊó®Âú®Â≠¶‰π†‰∏ÄÁßçÈÄöÁî®‰∏îÂèØËøÅÁßªÁöÑÂØπÊäóÂêéÁºÄÁîüÊàêÊ®°ÂûãÔºåÁî®‰∫éÂØπÈΩêÂêéÁöÑÂºÄÊîæÂíåÈó≠Ê∫êLLMsËøõË°åË∂äÁã±„ÄÇ\\n\\n### ÂàõÊñ∞ÁÇπ\\n1. **AmpleGCGÊ®°Âûã**Ôºö\\n   - **ÈÄöÁî®ÊÄß**ÔºöAmpleGCGËÉΩÂ§ü‰∏∫‰ªª‰ΩïÊúâÂÆ≥Êü•ËØ¢ÁîüÊàêÂÆöÂà∂ÂåñÁöÑÂØπÊäóÂêéÁºÄÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÊîªÂáª„ÄÇ\\n   - **È´òÊïàÊÄß**ÔºöËØ•Ê®°ÂûãËÉΩÂ§üÂú®Âá†ÁßíÈíüÂÜÖÁîüÊàêÊï∞Áôæ‰∏™ÂØπÊäóÂêéÁºÄÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊîªÂáªÁöÑÊàêÂäüÁéáÂíåÊïàÁéá„ÄÇ\\n   - **ÂèØËøÅÁßªÊÄß**ÔºöAmpleGCG‰∏ç‰ªÖÈÄÇÁî®‰∫éÂºÄÊîæÊ∫êÁ†ÅÊ®°ÂûãÔºàÂ¶ÇLlama-2-7B-chatÂíåVicuna-7BÔºâÔºåËøòËÉΩÊó†ÁºùËøÅÁßªÂà∞Èó≠Ê∫êÊ®°ÂûãÔºàÂ¶ÇÊúÄÊñ∞ÁöÑGPT-3.5ÔºâÔºåÊòæÁ§∫Âá∫ÂÖ∂ÂπøÊ≥õÁöÑÈÄÇÁî®ÊÄß„ÄÇ\\n\\n2. **‰ºòÂåñÁ≠ñÁï•ÊîπËøõ**Ôºö\\n   - **ÊçüÂ§±ÂáΩÊï∞ÁöÑÂ±ÄÈôêÊÄß**ÔºöËÆ∫ÊñáÊåáÂá∫ÔºåÂú®GCG‰ºòÂåñËøáÁ®ã‰∏≠Ôºå‰ªÖÈÄâÊã©ÊçüÂ§±ÊúÄ‰ΩéÁöÑÂêéÁºÄÂπ∂‰∏çÊòØÊúÄ‰Ω≥Á≠ñÁï•ÔºåÂõ†‰∏∫ËøôÂèØËÉΩÂØºËá¥ÈîôËøáËÆ∏Â§öÊúâÊïàÁöÑÂêéÁºÄ„ÄÇ\\n   - **Â¢ûÂº∫ÂûãGCG**ÔºöÈÄöËøáÊî∂ÈõÜÊâÄÊúâ‰∏≠Èó¥Ê≠•È™§ÁöÑÂÄôÈÄâÂêéÁºÄÂπ∂ËøõË°åËØÑ‰º∞ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊîªÂáªÊàêÂäüÁéáÔºàASRÔºâÂíåÂèëÁé∞ÁöÑÊúâÊïàÂêéÁºÄÊï∞Èáè„ÄÇ\\n\\n3. **Èò≤Âæ°Êú∫Âà∂ÁöÑËßÑÈÅø**Ôºö\\n   - **Âõ∞ÊÉëÂ∫¶Èò≤Âæ°ÁöÑÁ™ÅÁ†¥**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏§ÁßçÊäÄÂ∑ßÔºàAmpleGCG Input RepeatÂíåAmpleGCG Input DirectÔºâÔºåÈÄöËøáÈáçÂ§çÂéüÂßãÊü•ËØ¢Êù•Èôç‰ΩéÁîüÊàêÊñáÊú¨ÁöÑÂõ∞ÊÉëÂ∫¶Ôºå‰ªéËÄåÊàêÂäüËßÑÈÅøÂü∫‰∫éÂõ∞ÊÉëÂ∫¶ÁöÑÈò≤Âæ°Êú∫Âà∂„ÄÇ\\n\\n4. **ÂÆûÈ™åÈ™åËØÅ**Ôºö\\n   - **È´òÊàêÂäüÁéá**ÔºöAmpleGCGÂú®Â§ö‰∏™Ê®°Âûã‰∏äÂÆûÁé∞‰∫ÜÊé•Ëøë100%ÁöÑÊîªÂáªÊàêÂäüÁéáÔºåËøúË∂ÖÁé∞ÊúâÂü∫Á∫øÊñπÊ≥ï„ÄÇ\\n   - **Â§öÊ†∑ÊÄß**ÔºöÁîüÊàêÁöÑÂØπÊäóÂêéÁºÄÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÂ§öÊ†∑ÊÄßÔºåË°®ÊòéËØ•Ê®°ÂûãËÉΩÂ§üË¶ÜÁõñÊõ¥Â§öÊΩúÂú®ÁöÑÊºèÊ¥û„ÄÇ\\n\\n5. **‰º¶ÁêÜ‰∏éË¥£‰ªª**Ôºö\\n   - ËÆ∫ÊñáÂº∫Ë∞É‰∫ÜÁ†îÁ©∂ÊàêÊûúÁöÑÊΩúÂú®È£éÈô©ÔºåÂπ∂ÊâøËØ∫Ë¥üË¥£‰ªªÂú∞ÂàÜ‰∫´Ëøô‰∫õÂèëÁé∞Ôºå‰ª•‰øÉËøõÊõ¥Âº∫Â§ßÁöÑÈò≤Âæ°Á≠ñÁï•ÁöÑÂºÄÂèë„ÄÇ\\n\\nÊÄªÁªìÊù•ËØ¥ÔºåËøôÁØáËÆ∫ÊñáÈÄöËøáÊèêÂá∫AmpleGCGÊ®°ÂûãÔºå‰∏ç‰ªÖÊèêÂçá‰∫ÜÂØπÊäóÂêéÁºÄÁîüÊàêÁöÑÊïàÁéáÂíåÊàêÂäüÁéáÔºåËøòÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®‰∏çÂêåÊ®°Âûã‰∏äÁöÑÂπøÊ≥õÈÄÇÁî®ÊÄßÂíåÂØπÁé∞ÊúâÈò≤Âæ°Êú∫Âà∂ÁöÑÁ™ÅÁ†¥ËÉΩÂäõÔºå‰∏∫LLMsÁöÑÂÆâÂÖ®ÊÄßÁ†îÁ©∂Êèê‰æõ‰∫ÜÈáçË¶ÅÁöÑËßÅËß£ÂíåÂ∑•ÂÖ∑„ÄÇ', 'reasoning_content': '', 'role': 'assistant'}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None}], 'object': 'chat.completion', 'usage': {'prompt_tokens': 9482, 'completion_tokens': 575, 'total_tokens': 10057}, 'created': 1753780188, 'system_fingerprint': None, 'model': 'qwen3-32b', 'id': 'chatcmpl-b78beed3-56dd-95ed-a2e7-260aa0c6d9e8'}\n", "record": {"elapsed": {"repr": "0:01:18.487734", "seconds": 78.487734}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "onlineChatModuleBase.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/module/llms/onlineChatModule/onlineChatModuleBase.py"}, "function": "_str_to_json", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 204, "message": "message: {'choices': [{'message': {'content': 'ËøôÁØáËÆ∫Êñá„ÄäLearning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs„ÄãÁöÑ‰∏ªË¶Å‰∏ªÈ¢òËßÇÁÇπÂíåÂàõÊñ∞ÁÇπÂ¶Ç‰∏ãÔºö\\n\\n### ‰∏ªÈ¢òËßÇÁÇπ\\n1. **ÂÆâÂÖ®ÂØπÈΩêÁöÑÊåëÊàò**ÔºöÈöèÁùÄÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Ëá™‰∏ªÁ≥ªÁªü‰∏≠ÁöÑÂπøÊ≥õÂ∫îÁî®ÔºåÁ°Æ‰øùÂÖ∂ÂÆâÂÖ®ÊÄßÂèòÂæóÂ∞§‰∏∫ÈáçË¶Å„ÄÇÂ∞ΩÁÆ°Â∑≤ÊúâÂ§ßÈáèÁ†îÁ©∂Ëá¥Âäõ‰∫éÊèêÂçáLLMsÁöÑÂÆâÂÖ®ÊÄßÔºå‰ΩÜÊîªÂáªËÄÖ‰ªçËÉΩÈÄöËøá‚ÄúË∂äÁã±‚ÄùÊâãÊÆµÁªïËøáËøô‰∫õÂÆâÂÖ®Êé™ÊñΩ„ÄÇ\\n2. **ÂØπÊäóÂêéÁºÄÁöÑÁîüÊàê**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊñπÊ≥ïÔºåÊó®Âú®Â≠¶‰π†‰∏ÄÁßçÈÄöÁî®‰∏îÂèØËøÅÁßªÁöÑÂØπÊäóÂêéÁºÄÁîüÊàêÊ®°ÂûãÔºåÁî®‰∫éÂØπÈΩêÂêéÁöÑÂºÄÊîæÂíåÈó≠Ê∫êLLMsËøõË°åË∂äÁã±„ÄÇ\\n\\n### ÂàõÊñ∞ÁÇπ\\n1. **AmpleGCGÊ®°Âûã**Ôºö\\n   - **ÈÄöÁî®ÊÄß**ÔºöAmpleGCGËÉΩÂ§ü‰∏∫‰ªª‰ΩïÊúâÂÆ≥Êü•ËØ¢ÁîüÊàêÂÆöÂà∂ÂåñÁöÑÂØπÊäóÂêéÁºÄÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÊîªÂáª„ÄÇ\\n   - **È´òÊïàÊÄß**ÔºöËØ•Ê®°ÂûãËÉΩÂ§üÂú®Âá†ÁßíÈíüÂÜÖÁîüÊàêÊï∞Áôæ‰∏™ÂØπÊäóÂêéÁºÄÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊîªÂáªÁöÑÊàêÂäüÁéáÂíåÊïàÁéá„ÄÇ\\n   - **ÂèØËøÅÁßªÊÄß**ÔºöAmpleGCG‰∏ç‰ªÖÈÄÇÁî®‰∫éÂºÄÊîæÊ∫êÁ†ÅÊ®°ÂûãÔºàÂ¶ÇLlama-2-7B-chatÂíåVicuna-7BÔºâÔºåËøòËÉΩÊó†ÁºùËøÅÁßªÂà∞Èó≠Ê∫êÊ®°ÂûãÔºàÂ¶ÇÊúÄÊñ∞ÁöÑGPT-3.5ÔºâÔºåÊòæÁ§∫Âá∫ÂÖ∂ÂπøÊ≥õÁöÑÈÄÇÁî®ÊÄß„ÄÇ\\n\\n2. **‰ºòÂåñÁ≠ñÁï•ÊîπËøõ**Ôºö\\n   - **ÊçüÂ§±ÂáΩÊï∞ÁöÑÂ±ÄÈôêÊÄß**ÔºöËÆ∫ÊñáÊåáÂá∫ÔºåÂú®GCG‰ºòÂåñËøáÁ®ã‰∏≠Ôºå‰ªÖÈÄâÊã©ÊçüÂ§±ÊúÄ‰ΩéÁöÑÂêéÁºÄÂπ∂‰∏çÊòØÊúÄ‰Ω≥Á≠ñÁï•ÔºåÂõ†‰∏∫ËøôÂèØËÉΩÂØºËá¥ÈîôËøáËÆ∏Â§öÊúâÊïàÁöÑÂêéÁºÄ„ÄÇ\\n   - **Â¢ûÂº∫ÂûãGCG**ÔºöÈÄöËøáÊî∂ÈõÜÊâÄÊúâ‰∏≠Èó¥Ê≠•È™§ÁöÑÂÄôÈÄâÂêéÁºÄÂπ∂ËøõË°åËØÑ‰º∞ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊîªÂáªÊàêÂäüÁéáÔºàASRÔºâÂíåÂèëÁé∞ÁöÑÊúâÊïàÂêéÁºÄÊï∞Èáè„ÄÇ\\n\\n3. **Èò≤Âæ°Êú∫Âà∂ÁöÑËßÑÈÅø**Ôºö\\n   - **Âõ∞ÊÉëÂ∫¶Èò≤Âæ°ÁöÑÁ™ÅÁ†¥**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏§ÁßçÊäÄÂ∑ßÔºàAmpleGCG Input RepeatÂíåAmpleGCG Input DirectÔºâÔºåÈÄöËøáÈáçÂ§çÂéüÂßãÊü•ËØ¢Êù•Èôç‰ΩéÁîüÊàêÊñáÊú¨ÁöÑÂõ∞ÊÉëÂ∫¶Ôºå‰ªéËÄåÊàêÂäüËßÑÈÅøÂü∫‰∫éÂõ∞ÊÉëÂ∫¶ÁöÑÈò≤Âæ°Êú∫Âà∂„ÄÇ\\n\\n4. **ÂÆûÈ™åÈ™åËØÅ**Ôºö\\n   - **È´òÊàêÂäüÁéá**ÔºöAmpleGCGÂú®Â§ö‰∏™Ê®°Âûã‰∏äÂÆûÁé∞‰∫ÜÊé•Ëøë100%ÁöÑÊîªÂáªÊàêÂäüÁéáÔºåËøúË∂ÖÁé∞ÊúâÂü∫Á∫øÊñπÊ≥ï„ÄÇ\\n   - **Â§öÊ†∑ÊÄß**ÔºöÁîüÊàêÁöÑÂØπÊäóÂêéÁºÄÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÂ§öÊ†∑ÊÄßÔºåË°®ÊòéËØ•Ê®°ÂûãËÉΩÂ§üË¶ÜÁõñÊõ¥Â§öÊΩúÂú®ÁöÑÊºèÊ¥û„ÄÇ\\n\\n5. **‰º¶ÁêÜ‰∏éË¥£‰ªª**Ôºö\\n   - ËÆ∫ÊñáÂº∫Ë∞É‰∫ÜÁ†îÁ©∂ÊàêÊûúÁöÑÊΩúÂú®È£éÈô©ÔºåÂπ∂ÊâøËØ∫Ë¥üË¥£‰ªªÂú∞ÂàÜ‰∫´Ëøô‰∫õÂèëÁé∞Ôºå‰ª•‰øÉËøõÊõ¥Âº∫Â§ßÁöÑÈò≤Âæ°Á≠ñÁï•ÁöÑÂºÄÂèë„ÄÇ\\n\\nÊÄªÁªìÊù•ËØ¥ÔºåËøôÁØáËÆ∫ÊñáÈÄöËøáÊèêÂá∫AmpleGCGÊ®°ÂûãÔºå‰∏ç‰ªÖÊèêÂçá‰∫ÜÂØπÊäóÂêéÁºÄÁîüÊàêÁöÑÊïàÁéáÂíåÊàêÂäüÁéáÔºåËøòÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®‰∏çÂêåÊ®°Âûã‰∏äÁöÑÂπøÊ≥õÈÄÇÁî®ÊÄßÂíåÂØπÁé∞ÊúâÈò≤Âæ°Êú∫Âà∂ÁöÑÁ™ÅÁ†¥ËÉΩÂäõÔºå‰∏∫LLMsÁöÑÂÆâÂÖ®ÊÄßÁ†îÁ©∂Êèê‰æõ‰∫ÜÈáçË¶ÅÁöÑËßÅËß£ÂíåÂ∑•ÂÖ∑„ÄÇ', 'reasoning_content': '', 'role': 'assistant'}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None}], 'object': 'chat.completion', 'usage': {'prompt_tokens': 9482, 'completion_tokens': 575, 'total_tokens': 10057}, 'created': 1753780188, 'system_fingerprint': None, 'model': 'qwen3-32b', 'id': 'chatcmpl-b78beed3-56dd-95ed-a2e7-260aa0c6d9e8'}", "module": "onlineChatModuleBase", "name": "lazyllm.module.llms.onlineChatModule.onlineChatModuleBase", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140539844355648, "name": "ThreadPoolExecutor-1_0"}, "time": {"repr": "2025-07-29 17:09:46.478741+08:00", "timestamp": 1753780186.478741}}}
{"text": "result: ËøôÁØáËÆ∫Êñá„ÄäLearning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs„ÄãÁöÑ‰∏ªË¶Å‰∏ªÈ¢òËßÇÁÇπÂíåÂàõÊñ∞ÁÇπÂ¶Ç‰∏ãÔºö\n\n### ‰∏ªÈ¢òËßÇÁÇπ\n1. **ÂÆâÂÖ®ÂØπÈΩêÁöÑÊåëÊàò**ÔºöÈöèÁùÄÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Ëá™‰∏ªÁ≥ªÁªü‰∏≠ÁöÑÂπøÊ≥õÂ∫îÁî®ÔºåÁ°Æ‰øùÂÖ∂ÂÆâÂÖ®ÊÄßÂèòÂæóÂ∞§‰∏∫ÈáçË¶Å„ÄÇÂ∞ΩÁÆ°Â∑≤ÊúâÂ§ßÈáèÁ†îÁ©∂Ëá¥Âäõ‰∫éÊèêÂçáLLMsÁöÑÂÆâÂÖ®ÊÄßÔºå‰ΩÜÊîªÂáªËÄÖ‰ªçËÉΩÈÄöËøá‚ÄúË∂äÁã±‚ÄùÊâãÊÆµÁªïËøáËøô‰∫õÂÆâÂÖ®Êé™ÊñΩ„ÄÇ\n2. **ÂØπÊäóÂêéÁºÄÁöÑÁîüÊàê**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊñπÊ≥ïÔºåÊó®Âú®Â≠¶‰π†‰∏ÄÁßçÈÄöÁî®‰∏îÂèØËøÅÁßªÁöÑÂØπÊäóÂêéÁºÄÁîüÊàêÊ®°ÂûãÔºåÁî®‰∫éÂØπÈΩêÂêéÁöÑÂºÄÊîæÂíåÈó≠Ê∫êLLMsËøõË°åË∂äÁã±„ÄÇ\n\n### ÂàõÊñ∞ÁÇπ\n1. **AmpleGCGÊ®°Âûã**Ôºö\n   - **ÈÄöÁî®ÊÄß**ÔºöAmpleGCGËÉΩÂ§ü‰∏∫‰ªª‰ΩïÊúâÂÆ≥Êü•ËØ¢ÁîüÊàêÂÆöÂà∂ÂåñÁöÑÂØπÊäóÂêéÁºÄÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÊîªÂáª„ÄÇ\n   - **È´òÊïàÊÄß**ÔºöËØ•Ê®°ÂûãËÉΩÂ§üÂú®Âá†ÁßíÈíüÂÜÖÁîüÊàêÊï∞Áôæ‰∏™ÂØπÊäóÂêéÁºÄÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊîªÂáªÁöÑÊàêÂäüÁéáÂíåÊïàÁéá„ÄÇ\n   - **ÂèØËøÅÁßªÊÄß**ÔºöAmpleGCG‰∏ç‰ªÖÈÄÇÁî®‰∫éÂºÄÊîæÊ∫êÁ†ÅÊ®°ÂûãÔºàÂ¶ÇLlama-2-7B-chatÂíåVicuna-7BÔºâÔºåËøòËÉΩÊó†ÁºùËøÅÁßªÂà∞Èó≠Ê∫êÊ®°ÂûãÔºàÂ¶ÇÊúÄÊñ∞ÁöÑGPT-3.5ÔºâÔºåÊòæÁ§∫Âá∫ÂÖ∂ÂπøÊ≥õÁöÑÈÄÇÁî®ÊÄß„ÄÇ\n\n2. **‰ºòÂåñÁ≠ñÁï•ÊîπËøõ**Ôºö\n   - **ÊçüÂ§±ÂáΩÊï∞ÁöÑÂ±ÄÈôêÊÄß**ÔºöËÆ∫ÊñáÊåáÂá∫ÔºåÂú®GCG‰ºòÂåñËøáÁ®ã‰∏≠Ôºå‰ªÖÈÄâÊã©ÊçüÂ§±ÊúÄ‰ΩéÁöÑÂêéÁºÄÂπ∂‰∏çÊòØÊúÄ‰Ω≥Á≠ñÁï•ÔºåÂõ†‰∏∫ËøôÂèØËÉΩÂØºËá¥ÈîôËøáËÆ∏Â§öÊúâÊïàÁöÑÂêéÁºÄ„ÄÇ\n   - **Â¢ûÂº∫ÂûãGCG**ÔºöÈÄöËøáÊî∂ÈõÜÊâÄÊúâ‰∏≠Èó¥Ê≠•È™§ÁöÑÂÄôÈÄâÂêéÁºÄÂπ∂ËøõË°åËØÑ‰º∞ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊîªÂáªÊàêÂäüÁéáÔºàASRÔºâÂíåÂèëÁé∞ÁöÑÊúâÊïàÂêéÁºÄÊï∞Èáè„ÄÇ\n\n3. **Èò≤Âæ°Êú∫Âà∂ÁöÑËßÑÈÅø**Ôºö\n   - **Âõ∞ÊÉëÂ∫¶Èò≤Âæ°ÁöÑÁ™ÅÁ†¥**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏§ÁßçÊäÄÂ∑ßÔºàAmpleGCG Input RepeatÂíåAmpleGCG Input DirectÔºâÔºåÈÄöËøáÈáçÂ§çÂéüÂßãÊü•ËØ¢Êù•Èôç‰ΩéÁîüÊàêÊñáÊú¨ÁöÑÂõ∞ÊÉëÂ∫¶Ôºå‰ªéËÄåÊàêÂäüËßÑÈÅøÂü∫‰∫éÂõ∞ÊÉëÂ∫¶ÁöÑÈò≤Âæ°Êú∫Âà∂„ÄÇ\n\n4. **ÂÆûÈ™åÈ™åËØÅ**Ôºö\n   - **È´òÊàêÂäüÁéá**ÔºöAmpleGCGÂú®Â§ö‰∏™Ê®°Âûã‰∏äÂÆûÁé∞‰∫ÜÊé•Ëøë100%ÁöÑÊîªÂáªÊàêÂäüÁéáÔºåËøúË∂ÖÁé∞ÊúâÂü∫Á∫øÊñπÊ≥ï„ÄÇ\n   - **Â§öÊ†∑ÊÄß**ÔºöÁîüÊàêÁöÑÂØπÊäóÂêéÁºÄÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÂ§öÊ†∑ÊÄßÔºåË°®ÊòéËØ•Ê®°ÂûãËÉΩÂ§üË¶ÜÁõñÊõ¥Â§öÊΩúÂú®ÁöÑÊºèÊ¥û„ÄÇ\n\n5. **‰º¶ÁêÜ‰∏éË¥£‰ªª**Ôºö\n   - ËÆ∫ÊñáÂº∫Ë∞É‰∫ÜÁ†îÁ©∂ÊàêÊûúÁöÑÊΩúÂú®È£éÈô©ÔºåÂπ∂ÊâøËØ∫Ë¥üË¥£‰ªªÂú∞ÂàÜ‰∫´Ëøô‰∫õÂèëÁé∞Ôºå‰ª•‰øÉËøõÊõ¥Âº∫Â§ßÁöÑÈò≤Âæ°Á≠ñÁï•ÁöÑÂºÄÂèë„ÄÇ\n\nÊÄªÁªìÊù•ËØ¥ÔºåËøôÁØáËÆ∫ÊñáÈÄöËøáÊèêÂá∫AmpleGCGÊ®°ÂûãÔºå‰∏ç‰ªÖÊèêÂçá‰∫ÜÂØπÊäóÂêéÁºÄÁîüÊàêÁöÑÊïàÁéáÂíåÊàêÂäüÁéáÔºåËøòÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®‰∏çÂêåÊ®°Âûã‰∏äÁöÑÂπøÊ≥õÈÄÇÁî®ÊÄßÂíåÂØπÁé∞ÊúâÈò≤Âæ°Êú∫Âà∂ÁöÑÁ™ÅÁ†¥ËÉΩÂäõÔºå‰∏∫LLMsÁöÑÂÆâÂÖ®ÊÄßÁ†îÁ©∂Êèê‰æõ‰∫ÜÈáçË¶ÅÁöÑËßÅËß£ÂíåÂ∑•ÂÖ∑„ÄÇ\n", "record": {"elapsed": {"repr": "0:01:18.489269", "seconds": 78.489269}, "exception": null, "extra": {"name": "lazyllm", "process": 162546}, "file": {"name": "onlineChatModuleBase.py", "path": "/home/lianghao/github/LazyLLM/lazyllm/module/llms/onlineChatModule/onlineChatModuleBase.py"}, "function": "_extract_and_format", "level": {"icon": "üêû", "name": "DEBUG", "no": 10}, "line": 267, "message": "result: ËøôÁØáËÆ∫Êñá„ÄäLearning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs„ÄãÁöÑ‰∏ªË¶Å‰∏ªÈ¢òËßÇÁÇπÂíåÂàõÊñ∞ÁÇπÂ¶Ç‰∏ãÔºö\n\n### ‰∏ªÈ¢òËßÇÁÇπ\n1. **ÂÆâÂÖ®ÂØπÈΩêÁöÑÊåëÊàò**ÔºöÈöèÁùÄÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Ëá™‰∏ªÁ≥ªÁªü‰∏≠ÁöÑÂπøÊ≥õÂ∫îÁî®ÔºåÁ°Æ‰øùÂÖ∂ÂÆâÂÖ®ÊÄßÂèòÂæóÂ∞§‰∏∫ÈáçË¶Å„ÄÇÂ∞ΩÁÆ°Â∑≤ÊúâÂ§ßÈáèÁ†îÁ©∂Ëá¥Âäõ‰∫éÊèêÂçáLLMsÁöÑÂÆâÂÖ®ÊÄßÔºå‰ΩÜÊîªÂáªËÄÖ‰ªçËÉΩÈÄöËøá‚ÄúË∂äÁã±‚ÄùÊâãÊÆµÁªïËøáËøô‰∫õÂÆâÂÖ®Êé™ÊñΩ„ÄÇ\n2. **ÂØπÊäóÂêéÁºÄÁöÑÁîüÊàê**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊñπÊ≥ïÔºåÊó®Âú®Â≠¶‰π†‰∏ÄÁßçÈÄöÁî®‰∏îÂèØËøÅÁßªÁöÑÂØπÊäóÂêéÁºÄÁîüÊàêÊ®°ÂûãÔºåÁî®‰∫éÂØπÈΩêÂêéÁöÑÂºÄÊîæÂíåÈó≠Ê∫êLLMsËøõË°åË∂äÁã±„ÄÇ\n\n### ÂàõÊñ∞ÁÇπ\n1. **AmpleGCGÊ®°Âûã**Ôºö\n   - **ÈÄöÁî®ÊÄß**ÔºöAmpleGCGËÉΩÂ§ü‰∏∫‰ªª‰ΩïÊúâÂÆ≥Êü•ËØ¢ÁîüÊàêÂÆöÂà∂ÂåñÁöÑÂØπÊäóÂêéÁºÄÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÊîªÂáª„ÄÇ\n   - **È´òÊïàÊÄß**ÔºöËØ•Ê®°ÂûãËÉΩÂ§üÂú®Âá†ÁßíÈíüÂÜÖÁîüÊàêÊï∞Áôæ‰∏™ÂØπÊäóÂêéÁºÄÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊîªÂáªÁöÑÊàêÂäüÁéáÂíåÊïàÁéá„ÄÇ\n   - **ÂèØËøÅÁßªÊÄß**ÔºöAmpleGCG‰∏ç‰ªÖÈÄÇÁî®‰∫éÂºÄÊîæÊ∫êÁ†ÅÊ®°ÂûãÔºàÂ¶ÇLlama-2-7B-chatÂíåVicuna-7BÔºâÔºåËøòËÉΩÊó†ÁºùËøÅÁßªÂà∞Èó≠Ê∫êÊ®°ÂûãÔºàÂ¶ÇÊúÄÊñ∞ÁöÑGPT-3.5ÔºâÔºåÊòæÁ§∫Âá∫ÂÖ∂ÂπøÊ≥õÁöÑÈÄÇÁî®ÊÄß„ÄÇ\n\n2. **‰ºòÂåñÁ≠ñÁï•ÊîπËøõ**Ôºö\n   - **ÊçüÂ§±ÂáΩÊï∞ÁöÑÂ±ÄÈôêÊÄß**ÔºöËÆ∫ÊñáÊåáÂá∫ÔºåÂú®GCG‰ºòÂåñËøáÁ®ã‰∏≠Ôºå‰ªÖÈÄâÊã©ÊçüÂ§±ÊúÄ‰ΩéÁöÑÂêéÁºÄÂπ∂‰∏çÊòØÊúÄ‰Ω≥Á≠ñÁï•ÔºåÂõ†‰∏∫ËøôÂèØËÉΩÂØºËá¥ÈîôËøáËÆ∏Â§öÊúâÊïàÁöÑÂêéÁºÄ„ÄÇ\n   - **Â¢ûÂº∫ÂûãGCG**ÔºöÈÄöËøáÊî∂ÈõÜÊâÄÊúâ‰∏≠Èó¥Ê≠•È™§ÁöÑÂÄôÈÄâÂêéÁºÄÂπ∂ËøõË°åËØÑ‰º∞ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊîªÂáªÊàêÂäüÁéáÔºàASRÔºâÂíåÂèëÁé∞ÁöÑÊúâÊïàÂêéÁºÄÊï∞Èáè„ÄÇ\n\n3. **Èò≤Âæ°Êú∫Âà∂ÁöÑËßÑÈÅø**Ôºö\n   - **Âõ∞ÊÉëÂ∫¶Èò≤Âæ°ÁöÑÁ™ÅÁ†¥**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏§ÁßçÊäÄÂ∑ßÔºàAmpleGCG Input RepeatÂíåAmpleGCG Input DirectÔºâÔºåÈÄöËøáÈáçÂ§çÂéüÂßãÊü•ËØ¢Êù•Èôç‰ΩéÁîüÊàêÊñáÊú¨ÁöÑÂõ∞ÊÉëÂ∫¶Ôºå‰ªéËÄåÊàêÂäüËßÑÈÅøÂü∫‰∫éÂõ∞ÊÉëÂ∫¶ÁöÑÈò≤Âæ°Êú∫Âà∂„ÄÇ\n\n4. **ÂÆûÈ™åÈ™åËØÅ**Ôºö\n   - **È´òÊàêÂäüÁéá**ÔºöAmpleGCGÂú®Â§ö‰∏™Ê®°Âûã‰∏äÂÆûÁé∞‰∫ÜÊé•Ëøë100%ÁöÑÊîªÂáªÊàêÂäüÁéáÔºåËøúË∂ÖÁé∞ÊúâÂü∫Á∫øÊñπÊ≥ï„ÄÇ\n   - **Â§öÊ†∑ÊÄß**ÔºöÁîüÊàêÁöÑÂØπÊäóÂêéÁºÄÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÂ§öÊ†∑ÊÄßÔºåË°®ÊòéËØ•Ê®°ÂûãËÉΩÂ§üË¶ÜÁõñÊõ¥Â§öÊΩúÂú®ÁöÑÊºèÊ¥û„ÄÇ\n\n5. **‰º¶ÁêÜ‰∏éË¥£‰ªª**Ôºö\n   - ËÆ∫ÊñáÂº∫Ë∞É‰∫ÜÁ†îÁ©∂ÊàêÊûúÁöÑÊΩúÂú®È£éÈô©ÔºåÂπ∂ÊâøËØ∫Ë¥üË¥£‰ªªÂú∞ÂàÜ‰∫´Ëøô‰∫õÂèëÁé∞Ôºå‰ª•‰øÉËøõÊõ¥Âº∫Â§ßÁöÑÈò≤Âæ°Á≠ñÁï•ÁöÑÂºÄÂèë„ÄÇ\n\nÊÄªÁªìÊù•ËØ¥ÔºåËøôÁØáËÆ∫ÊñáÈÄöËøáÊèêÂá∫AmpleGCGÊ®°ÂûãÔºå‰∏ç‰ªÖÊèêÂçá‰∫ÜÂØπÊäóÂêéÁºÄÁîüÊàêÁöÑÊïàÁéáÂíåÊàêÂäüÁéáÔºåËøòÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®‰∏çÂêåÊ®°Âûã‰∏äÁöÑÂπøÊ≥õÈÄÇÁî®ÊÄßÂíåÂØπÁé∞ÊúâÈò≤Âæ°Êú∫Âà∂ÁöÑÁ™ÅÁ†¥ËÉΩÂäõÔºå‰∏∫LLMsÁöÑÂÆâÂÖ®ÊÄßÁ†îÁ©∂Êèê‰æõ‰∫ÜÈáçË¶ÅÁöÑËßÅËß£ÂíåÂ∑•ÂÖ∑„ÄÇ", "module": "onlineChatModuleBase", "name": "lazyllm.module.llms.onlineChatModule.onlineChatModuleBase", "process": {"id": 162546, "name": "MainProcess"}, "thread": {"id": 140539844355648, "name": "ThreadPoolExecutor-1_0"}, "time": {"repr": "2025-07-29 17:09:46.480276+08:00", "timestamp": 1753780186.480276}}}
